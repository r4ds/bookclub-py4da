[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Python for Data Analysis Book Club",
    "section": "",
    "text": "This is a companion for the book Python for Data Analysis, 3E by Wes McKinney.\nThis website is being developed by the R4DS Online Learning Community. Follow along and join the community to participate.\nThis companion follows the R4DS Online Learning Community Code of Conduct."
  },
  {
    "objectID": "index.html#book-club-meetings",
    "href": "index.html#book-club-meetings",
    "title": "Python for Data Analysis Book Club",
    "section": "Book club meetings",
    "text": "Book club meetings\n\nEach week, a volunteer will present a chapter from the book.\n\nThis is the best way to learn the material.\n\nPresentations will usually consist of a review of the material, a discussion, and/or a demonstration of the principles presented in that chapter.\nMore information about how to present is available in the GitHub repo.\nPresentations will be recorded and will be available on the R4DS Online Learning Community YouTube Channel."
  },
  {
    "objectID": "01_notes.html",
    "href": "01_notes.html",
    "title": "Notes",
    "section": "",
    "text": "One of the most important languages for data science, machine learning, and general software development in academia and industry."
  },
  {
    "objectID": "01_notes.html#essential-python-libraries",
    "href": "01_notes.html#essential-python-libraries",
    "title": "Notes",
    "section": "Essential Python Libraries",
    "text": "Essential Python Libraries\n\nNumPy ( Numerical Python)\nPandas\nMatplotlib\nIpython and Jupyter\nScipy\nSklearn\nStatsModel"
  },
  {
    "objectID": "01_notes.html#numpy",
    "href": "01_notes.html#numpy",
    "title": "Notes",
    "section": "Numpy",
    "text": "Numpy\n\nShort for Numerical Python, has long been a cornerstone of numerical computing in Python. It provides the data structures, algorithms, and library glue needed for most scientific applications involving numerical data in Python"
  },
  {
    "objectID": "01_notes.html#pandas",
    "href": "01_notes.html#pandas",
    "title": "Notes",
    "section": "Pandas",
    "text": "Pandas\n\npandas provides high-level data structures and functions designed to make working with structured or tabular data intuitive and flexible.\n\n\nIt provides convenient indexing functionality to enable you to reshape, slice and dice, perform aggregations, and select subsets of data. Since data manipulation, preparation, and cleaning is such an important skill in data analysis,\nSee R vs Pandas comparison"
  },
  {
    "objectID": "01_notes.html#matplotlib",
    "href": "01_notes.html#matplotlib",
    "title": "Notes",
    "section": "Matplotlib",
    "text": "Matplotlib\n\nis the most popular Python library for producing plots and other two-dimensional data visualizations"
  },
  {
    "objectID": "01_notes.html#ipython-and-jupyter",
    "href": "01_notes.html#ipython-and-jupyter",
    "title": "Notes",
    "section": "IPython and Jupyter",
    "text": "IPython and Jupyter\n\nThe IPython system can now be used as a kernel (a programming language mode) for using Python with Jupyter."
  },
  {
    "objectID": "01_notes.html#scipy",
    "href": "01_notes.html#scipy",
    "title": "Notes",
    "section": "SciPy",
    "text": "SciPy\n\nSciPy is a collection of packages addressing a number of foundational problems in scientific computing."
  },
  {
    "objectID": "01_notes.html#scikit-learn",
    "href": "01_notes.html#scikit-learn",
    "title": "Notes",
    "section": "Scikit-learn",
    "text": "Scikit-learn\n\ngeneral-purpose machine learning toolkit for Python programmers."
  },
  {
    "objectID": "01_notes.html#statsmodels",
    "href": "01_notes.html#statsmodels",
    "title": "Notes",
    "section": "Statsmodels",
    "text": "Statsmodels\n\nis a statistical analysis package\n\n\nCompared with scikit-learn, statsmodels contains algorithms for classical (primarily frequentist) statistics and econometrics."
  },
  {
    "objectID": "01_notes.html#other-packages",
    "href": "01_notes.html#other-packages",
    "title": "Notes",
    "section": "Other Packages",
    "text": "Other Packages\n\nTensorFlow or PyTorch or Keras"
  },
  {
    "objectID": "01_notes.html#installing-necessary-packages",
    "href": "01_notes.html#installing-necessary-packages",
    "title": "Notes",
    "section": "Installing Necessary Packages",
    "text": "Installing Necessary Packages\n\nWe can install Python packages using “Pip” or “Conda”. Read more about pip vs python\n\nThe author recommends:\n\nMiniconda, a minimal installation of the conda package manager, along with conda-forge, a community-maintained software distribution based on conda.\nThis book uses Python 3.10 throughout."
  },
  {
    "objectID": "01_notes.html#mini-conda",
    "href": "01_notes.html#mini-conda",
    "title": "Notes",
    "section": "Mini-conda",
    "text": "Mini-conda\n\nConda is a packaging tool and installer that aims to do more than what pip does; handle library dependencies outside of the Python packages as well as the Python packages themselves. Conda also creates a virtual environment, like virtualenv does"
  },
  {
    "objectID": "01_notes.html#mini-forge",
    "href": "01_notes.html#mini-forge",
    "title": "Notes",
    "section": "Mini-forge",
    "text": "Mini-forge\n\nminiforge is the community (conda-forge) driven minimalistic conda installer. Subsequent package installations come thus from conda-forge channel. Mini-forge\nminiconda is the Anaconda (company) driven minimalistic conda installer. Subsequent package installations come from the anaconda channels (default or otherwise).\nminiforge started because miniconda doens’t support aarch64, very quickly the ‘PyPy’ people jumped on board, and in the mean time there are also miniforge versions for all Linux architectures, as well as MacOS.\nAARCH64, sometimes also referred to as ARM64, is a CPU architecture developed by ARM Ltd., and a 64-bit extension of the pre-existing ARM architecture. ARM architectures are primarily known for their energy efficiency and low power consumption. For that reason, virtually all mobile phones and tablets today use ARM architecture-based CPUs.\nAlthough AARCH64 and x64 (Intel, AMD, …) are both 64-bit CPU architectures, their inner basics are vastly different. Programs compiled for one platform, won’t work on the other (except with some magic), and vice-versa. That means, software does not only need to be recompiled, but often requires extensive optimization for either platform.\n\n\nThe first step is to configure conda-forge as your default package channel by running the following commands in a shell:\n\n\n! conda config --add channels conda-forge\n! conda config --set channel_priority strict\n\nWarning: 'conda-forge' already in 'channels' list, moving to the top\n\n\nNow, we will install the essential packages used throughout the book (along with their dependencies) with conda install\n\nconda create -y -n pydata-book python=3.10 # create enviroment with python 3.10 installed\nconda activate pydata-book # activate enviroment \n(pydata-book) $ conda install -y pandas jupyter matplotlib # install a\n\nInstall complete packages used in the the book\nconda install lxml beautifulsoup4 html5lib openpyxl\nrequests sqlalchemy seaborn scipy statsmodels\npatsy scikit-learn pyarrow pytables numba"
  },
  {
    "objectID": "01_notes.html#should-i-use-pip-or-conda",
    "href": "01_notes.html#should-i-use-pip-or-conda",
    "title": "Notes",
    "section": "Should I use Pip or Conda ?",
    "text": "Should I use Pip or Conda ?\n\nWhile you can use both conda and pip to install packages, you should avoid updating packages originally installed with conda using pip (and vice versa), as doing so can lead to environment problems. I recommend sticking to conda if you can and falling back on pip only for packages which are unavailable with conda install.\n\n\nconda install should always be preferred, but some packages are not available through conda so if conda install $package_name fails, try pip install $package_name."
  },
  {
    "objectID": "01_notes.html#what-can-we-do-with-conda",
    "href": "01_notes.html#what-can-we-do-with-conda",
    "title": "Notes",
    "section": "What can we do with Conda?",
    "text": "What can we do with Conda?\n\nMany commands : create env, activate env, delete env, lists env\nInstall tldr (https://github.com/tldr-pages/tldr) : The tldr-pages project is a collection of community-maintained help pages for command-line tools, that aims to be a simpler, more approachable complement to traditional"
  },
  {
    "objectID": "01_notes.html#navigating-this-book",
    "href": "01_notes.html#navigating-this-book",
    "title": "Notes",
    "section": "Navigating This Book",
    "text": "Navigating This Book\n\nChapter two and three: provides prerequisite knowledge for the remainder of the book. If you have Python experienc you can skip\n\n\nChapter four : Numpy\n\n\nChapter five : Pandas\n\n\nChapter six : Data loading, Storage and File format\n\n\nChapter seven : Data cleaning and Preparation\n\n\nChpater eight : Data wrangling\n\n\nChapter Nine : Plotting and Visualization\n\n\nChapter 10 : Data agreegation and Group operation"
  },
  {
    "objectID": "01_notes.html#import-conventions",
    "href": "01_notes.html#import-conventions",
    "title": "Notes",
    "section": "Import Conventions",
    "text": "Import Conventions\n\nThe Python community has adopted a number of naming conventions for commonly used modules:\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport statsmodels as\n\nSyntaxError: invalid syntax (1580968464.py, line 5)\n\n\n\nThis means that when you see np.arange, this is a reference to the arange function in NumPy. This is done because it’s considered bad practice in Python software development to import everything (from numpy import *) from a large package like NumPy\n\n\nimport numpy as np \n\nx = np.random.random((64, 3, 32, 10)) \ny = np.random.random((32, 10)) \n\nz = np.maximum(x, y)"
  },
  {
    "objectID": "01_video.html",
    "href": "01_video.html",
    "title": "Video",
    "section": "",
    "text": "00:22:16    Isabella Velásquez: For more info on TidyTuesday: https://github.com/rfordatascience/tidytuesday#readme\n00:26:23    shamsuddeen:    https://docs.google.com/spreadsheets/d/1io_R_ZaGtzJcDF5KcY4hbgMBsJVi_4USE4JGsHcv9ug/edit#gid=0\n00:45:23    shamsuddeen:    https://github.com/conda-forge/miniforge\n00:59:07    shamsuddeen:    https://github.com/conda-forge/miniforge\n01:03:03    shamsuddeen:    https://blogs.shmuhammad.com/"
  },
  {
    "objectID": "02_video.html",
    "href": "02_video.html",
    "title": "Video",
    "section": "",
    "text": "LOG"
  },
  {
    "objectID": "03_main.html",
    "href": "03_main.html",
    "title": "3. Built-in Data Structures, Functions, and Files",
    "section": "",
    "text": "The data structures tuples, lists, dictionaries, and sets\nFunctions\nErrors and Exception Handling\nFiles and the Operating System"
  },
  {
    "objectID": "03_notes.html",
    "href": "03_notes.html",
    "title": "1  Data Structures and Sequences",
    "section": "",
    "text": "A tuple is a fixed-length, immutable sequence of Python objects which, once assigned, cannot be changed. The easiest way to create one is with a comma-separated sequence of values wrapped in parentheses:\n\ntup = (4, 5, 6)\ntup\n\n(4, 5, 6)\n\n\nIn many contexts, the parentheses can be omitted\n\ntup = 4, 5, 6\ntup\n\n(4, 5, 6)\n\n\nYou can convert any sequence or iterator to a tuple by invoking\n\ntuple([4,0,2])\n\ntup = tuple('string')\n\ntup\n\n('s', 't', 'r', 'i', 'n', 'g')\n\n\nElements can be accessed with square brackets []\nNote the zero indexing\n\ntup[0]\n\n's'\n\n\nTuples of tuples\n\nnested_tup = (4,5,6),(7,8)\n\nnested_tup\n\n((4, 5, 6), (7, 8))\n\n\n\nnested_tup[0]\n\n(4, 5, 6)\n\n\n\nnested_tup[1]\n\n(7, 8)\n\n\nWhile the objects stored in a tuple may be mutable themselves, once the tuple is created it’s not possible to modify which object is stored in each slot:\n\ntup = tuple(['foo', [1, 2], True])\n\ntup[2]\n\nTrue\n\n\n```{python}\n\ntup[2] = False\n\n```\nTypeError                                 Traceback (most recent call last)\nInput In [9], in <cell line: 1>()\n----> 1 tup[2] = False\n\nTypeError: 'tuple' object does not support item assignment\nTypeError: 'tuple' object does not support item assignment\nIf an object inside a tuple is mutable, such as a list, you can modify it in place\n\ntup[1].append(3)\n\ntup\n\n('foo', [1, 2, 3], True)\n\n\nYou can concatenate tuples using the + operator to produce longer tuples:\n\n(4, None, 'foo') + (6, 0) + ('bar',)\n\n(4, None, 'foo', 6, 0, 'bar')\n\n\n\n\nIf you try to assign to a tuple-like expression of variables, Python will attempt to unpack the value on the righthand side of the equals sign:\n\ntup = (4, 5, 6)\ntup\n\n(4, 5, 6)\n\n\n\na, b, c = tup\n\nc\n\n6\n\n\nEven sequences with nested tuples can be unpacked:\n\ntup = 4, 5, (6,7)\n\na, b, (c, d) = tup\n\nd\n\n7\n\n\nTo easily swap variable names\n\na, b = 1, 4\n\na\n\n1\n\n\n\nb\n\n4\n\n\n\nb, a = a, b\n\na\n\n4\n\n\n\nb\n\n1\n\n\nA common use of variable unpacking is iterating over sequences of tuples or lists\n\nseq = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]\n\nseq\n\n[(1, 2, 3), (4, 5, 6), (7, 8, 9)]\n\n\n\nfor a, b, c in seq:\n     print(f'a={a}, b={b}, c={c}')\n\na=1, b=2, c=3\na=4, b=5, c=6\na=7, b=8, c=9\n\n\n*rest syntax for plucking elements\n\nvalues = 1,2,3,4,5\n\na, b, *rest = values\n\nrest\n\n[3, 4, 5]\n\n\nAs a matter of convention, many Python programmers will use the underscore (_) for unwanted variables:\n\na, b, *_ = values\n\n\n\n\nSince the size and contents of a tuple cannot be modified, it is very light on instance methods. A particularly useful one (also available on lists) is count\n\na = (1,2,2,2,2,3,4,5,7,8,9)\n\na.count(2)\n\n4"
  },
  {
    "objectID": "03_notes.html#list",
    "href": "03_notes.html#list",
    "title": "1  Data Structures and Sequences",
    "section": "1.2 List",
    "text": "1.2 List\n\nIn contrast with tuples, lists are variable length and their contents can be modified in place.\nLists are mutable.\nLists use [] square brackts or the list function\n\na_list = [2, 3, 7, None]\n\ntup = (\"foo\", \"bar\", \"baz\")\n\nb_list = list(tup)\n\nb_list\n\n['foo', 'bar', 'baz']\n\n\n\nb_list[1] = \"peekaboo\"\n\nb_list\n\n['foo', 'peekaboo', 'baz']\n\n\nLists and tuples are semantically similar (though tuples cannot be modified) and can be used interchangeably in many functions.\n\ngen = range(10)\n\ngen\n\nrange(0, 10)\n\n\n\nlist(gen)\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n\n1.2.1 Adding and removing list elements\nthe append method\n\nb_list.append(\"dwarf\")\n\nb_list\n\n['foo', 'peekaboo', 'baz', 'dwarf']\n\n\nthe insert method\n\nb_list.insert(1, \"red\")\n\nb_list\n\n['foo', 'red', 'peekaboo', 'baz', 'dwarf']\n\n\ninsert is computationally more expensive than append\nthe pop method, the inverse of insert\n\nb_list.pop(2)\n\n'peekaboo'\n\n\n\nb_list\n\n['foo', 'red', 'baz', 'dwarf']\n\n\nthe remove method\n\nb_list.append(\"foo\")\n\nb_list\n\n['foo', 'red', 'baz', 'dwarf', 'foo']\n\n\n\nb_list.remove(\"foo\")\n\nb_list\n\n['red', 'baz', 'dwarf', 'foo']\n\n\nCheck if a list contains a value using the in keyword:\n\n\"dwarf\" in b_list\n\nTrue\n\n\nThe keyword not can be used to negate an in\n\n\"dwarf\" not in b_list\n\nFalse\n\n\n\n\n1.2.2 Concatenating and combining lists\nsimilar with tuples, use + to concatenate\n\n[4, None, \"foo\"] + [7, 8, (2, 3)]\n\n[4, None, 'foo', 7, 8, (2, 3)]\n\n\nthe extend method\n\nx = [4, None, \"foo\"]\n\nx.extend([7,8,(2,3)])\n\nx\n\n[4, None, 'foo', 7, 8, (2, 3)]\n\n\nlist concatenation by addition is an expensive operation\nusing extend is preferable\n```{python}\neverything = []\nfor chunk in list_of_lists:\n    everything.extend(chunk)\n\n```\nis generally faster than\n```{python}\n\neverything = []\nfor chunk in list_of_lists:\n    everything = everything + chunk\n\n```\n\n\n1.2.3 Sorting\nthe sort method\n\na = [7, 2, 5, 1, 3]\n\na.sort()\n\na\n\n[1, 2, 3, 5, 7]\n\n\nsort options\n\nb = [\"saw\", \"small\", \"He\", \"foxes\", \"six\"]\n\nb.sort(key = len)\n\nb\n\n['He', 'saw', 'six', 'small', 'foxes']\n\n\n\n\n1.2.4 Slicing\nSlicing semantics takes a bit of getting used to, especially if you’re coming from R or MATLAB.\nusing the indexing operator []\n\nseq = [7, 2, 3, 7, 5, 6, 0, 1]\n\nseq[3:5]\n\n[7, 5]\n\n\nalso assigned with a sequence\n\nseq[3:5] = [6,3]\n\nseq\n\n[7, 2, 3, 6, 3, 6, 0, 1]\n\n\nEither the start or stop can be omitted\n\nseq[:5]\n\n[7, 2, 3, 6, 3]\n\n\n\nseq[3:]\n\n[6, 3, 6, 0, 1]\n\n\nNegative indices slice the sequence relative to the end:\n\nseq[-4:]\n\n[3, 6, 0, 1]\n\n\nA step can also be used after a second colon to, say, take every other element:\n\nseq[::2]\n\n[7, 3, 3, 0]\n\n\nA clever use of this is to pass -1, which has the useful effect of reversing a list or tuple:\n\nseq[::-1]\n\n[1, 0, 6, 3, 6, 3, 2, 7]"
  },
  {
    "objectID": "03_notes.html#dictionary",
    "href": "03_notes.html#dictionary",
    "title": "1  Data Structures and Sequences",
    "section": "1.3 Dictionary",
    "text": "1.3 Dictionary\n\nThe dictionary or dict may be the most important built-in Python data structure.\nOne approach for creating a dictionary is to use curly braces {} and colons to separate keys and values:\n\nempty_dict = {}\n\nd1 = {\"a\": \"some value\", \"b\": [1, 2, 3, 4]}\n\nd1\n\n{'a': 'some value', 'b': [1, 2, 3, 4]}\n\n\naccess, insert, or set elements\n\nd1[7] = \"an integer\"\n\nd1\n\n{'a': 'some value', 'b': [1, 2, 3, 4], 7: 'an integer'}\n\n\nand as before\n\n\"b\" in d1\n\nTrue\n\n\nthe del and pop methods\n\ndel d1[7]\n\nd1\n\n{'a': 'some value', 'b': [1, 2, 3, 4]}\n\n\n\nret = d1.pop(\"a\")\n\nret\n\n'some value'\n\n\nThe keys and values methods\n\nlist(d1.keys())\n\n['b']\n\n\n\nlist(d1.values())\n\n[[1, 2, 3, 4]]\n\n\nthe items method\n\nlist(d1.items())\n\n[('b', [1, 2, 3, 4])]\n\n\nthe update method to merge one dictionary into another\n\nd1.update({\"b\": \"foo\", \"c\": 12})\n\nd1\n\n{'b': 'foo', 'c': 12}\n\n\n### Creating dictionaries from sequences\n\nlist(range(5))\n\n[0, 1, 2, 3, 4]\n\n\n\ntuples = zip(range(5), reversed(range(5)))\n\ntuples\n\nmapping = dict(tuples)\n\nmapping\n\n{0: 4, 1: 3, 2: 2, 3: 1, 4: 0}\n\n\n\n1.3.1 Default values\nimagine categorizing a list of words by their first letters as a dictionary of lists\n\nwords = [\"apple\", \"bat\", \"bar\", \"atom\", \"book\"]\n\nby_letter = {}\n\nfor word in words:\n        letter = word[0]\n        if letter not in by_letter:\n            by_letter[letter] = [word]\n        else:\n            by_letter[letter].append(word)\n\nby_letter\n\n{'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']}\n\n\nThe setdefault dictionary method can be used to simplify this workflow. The preceding for loop can be rewritten as:\n\nby_letter = {}\n\nfor word in words:\n        letter = word[0]\n        by_letter.setdefault(letter, []).append(word)\n\nby_letter\n\n{'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']}\n\n\nThe built-in collectionsmodule has a useful class, defaultdict, which makes this even easier.\n\nfrom collections import defaultdict\n\nby_letter = defaultdict(list)\n\nfor word in words:\n        by_letter[word[0]].append(word)\n\nby_letter\n\ndefaultdict(list, {'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']})\n\n\n\n\n1.3.2 Valid dictionary key types\nkeys generally have to be immutable objects like scalars or tuples for hashability\nTo use a list as a key, one option is to convert it to a tuple, which can be hashed as long as its elements also can be:\n\nd = {}\n\nd[tuple([1,2,3])] = 5\n\nd\n\n{(1, 2, 3): 5}"
  },
  {
    "objectID": "03_notes.html#set",
    "href": "03_notes.html#set",
    "title": "1  Data Structures and Sequences",
    "section": "1.4 Set",
    "text": "1.4 Set\n\ncan be created in two ways: via the set function or via a set literal with curly braces:\n\nset([2, 2, 2, 1, 3, 3])\n\n{2,2,1,3,3}\n\n{1, 2, 3}\n\n\nSets support mathematical set operations like union, intersection, difference, and symmetric difference.\nThe union of these two sets:\n\na = {1, 2, 3, 4, 5}\n\nb = {3, 4, 5, 6, 7, 8}\n\na.union(b)\n\na | b\n\n{1, 2, 3, 4, 5, 6, 7, 8}\n\n\nThe &operator or the intersection method\n\na.intersection(b)\n\na & b\n\n{3, 4, 5}\n\n\nA table of commonly used set methods\nAll of the logical set operations have in-place counterparts, which enable you to replace the contents of the set on the left side of the operation with the result. For very large sets, this may be more efficient\n\nc = a.copy()\n\nc |= b\n\nc\n\n{1, 2, 3, 4, 5, 6, 7, 8}\n\n\n\nd = a.copy()\n\nd &= b\n\nd\n\n{3, 4, 5}\n\n\nset elements generally must be immutable, and they must be hashable\nyou can convert them to tuples\nYou can also check if a set is a subset of (is contained in) or a superset of (contains all elements of) another set\n\na_set = {1, 2, 3, 4, 5}\n\n{1, 2, 3}.issubset(a_set)\n\nTrue\n\n\n\na_set.issuperset({1, 2, 3})\n\nTrue"
  },
  {
    "objectID": "03_notes.html#built-in-sequence-functions",
    "href": "03_notes.html#built-in-sequence-functions",
    "title": "1  Data Structures and Sequences",
    "section": "1.5 Built-In Sequence Functions",
    "text": "1.5 Built-In Sequence Functions\n\n1.5.1 enumerate\nenumerate returns a sequence of (i, value) tuples\n\n\n1.5.2 sorted\nsorted returns a new sorted list\n\nsorted([7,1,2,9,3,6,5,0,22])\n\n[0, 1, 2, 3, 5, 6, 7, 9, 22]\n\n\n\n\n1.5.3 zip\nzip “pairs” up the elements of a number of lists, tuples, or other sequences to create a list of tuples\n\nseq1 = [\"foo\", \"bar\", \"baz\"]\n\nseq2 = [\"one\", \"two\", \"three\"]\n\nzipped = zip(seq1, seq2)\n\nlist(zipped)\n\n[('foo', 'one'), ('bar', 'two'), ('baz', 'three')]\n\n\nzip can take an arbitrary number of sequences, and the number of elements it produces is determined by the shortest sequence\n\nseq3 = [False, True]\n\nlist(zip(seq1, seq2, seq3))\n\n[('foo', 'one', False), ('bar', 'two', True)]\n\n\nA common use of zip is simultaneously iterating over multiple sequences, possibly also combined with enumerate\n\nfor index, (a, b) in enumerate(zip(seq1, seq2)):\n    print(f\"{index}: {a}, {b}\")\n\n0: foo, one\n1: bar, two\n2: baz, three\n\n\nreversed iterates over the elements of a sequence in reverse order\n\nlist(reversed(range(10)))\n\n[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]"
  },
  {
    "objectID": "03_notes.html#list-set-and-dictionary-comprehensions",
    "href": "03_notes.html#list-set-and-dictionary-comprehensions",
    "title": "1  Data Structures and Sequences",
    "section": "1.6 List, Set, and Dictionary Comprehensions",
    "text": "1.6 List, Set, and Dictionary Comprehensions\n[expr for value in collection if condition]\nFor example, given a list of strings, we could filter out strings with length 2 or less and convert them to uppercase like this\n\nstrings = [\"a\", \"as\", \"bat\", \"car\", \"dove\", \"python\"]\n\n[x.upper() for x in strings if len(x) > 2]\n\n['BAT', 'CAR', 'DOVE', 'PYTHON']\n\n\nA dictionary comprehension looks like this\ndict_comp = {key-expr: value-expr for value in collection\n             if condition}\nSuppose we wanted a set containing just the lengths of the strings contained in the collection\n\nunique_lengths = {len(x) for x in strings}\n\nunique_lengths\n\n{1, 2, 3, 4, 6}\n\n\nwe could create a lookup map of these strings for their locations in the list\n\nloc_mapping = {value: index for index, value in enumerate(strings)}\n\nloc_mapping\n\n{'a': 0, 'as': 1, 'bat': 2, 'car': 3, 'dove': 4, 'python': 5}"
  },
  {
    "objectID": "03_notes.html#nested-list-comprehensions",
    "href": "03_notes.html#nested-list-comprehensions",
    "title": "1  Data Structures and Sequences",
    "section": "1.7 Nested list comprehensions",
    "text": "1.7 Nested list comprehensions\nSuppose we have a list of lists containing some English and Spanish names. We want to get a single list containing all names with two or more a’s in them\n\nall_data = [[\"John\", \"Emily\", \"Michael\", \"Mary\", \"Steven\"],\n            [\"Maria\", \"Juan\", \"Javier\", \"Natalia\", \"Pilar\"]]\n\nresult = [name for names in all_data for name in names\n          if name.count(\"a\") >= 2]\n\nresult\n\n['Maria', 'Natalia']\n\n\nHere is another example where we “flatten” a list of tuples of integers into a simple list of integers\n\nsome_tuples = [(1, 2, 3), (4, 5, 6), (7, 8, 9)]\n\nflattened = [x for tup in some_tuples for x in tup]\n\nflattened\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9]"
  },
  {
    "objectID": "03_notes.html#namespaces-scope-and-local-functions",
    "href": "03_notes.html#namespaces-scope-and-local-functions",
    "title": "1  Data Structures and Sequences",
    "section": "2.1 Namespaces, Scope, and Local Functions",
    "text": "2.1 Namespaces, Scope, and Local Functions\nA more descriptive name describing a variable scope in Python is a namespace.\nConsider the following function\n\na = []\n\ndef func():\n    for i in range(5):\n        a.append(i)\n\nWhen func() is called, the empty list a is created, five elements are appended, and then a is destroyed when the function exits.\n\nfunc()\n\nfunc()\n\na\n\n[0, 1, 2, 3, 4, 0, 1, 2, 3, 4]"
  },
  {
    "objectID": "03_notes.html#returing-multiple-values",
    "href": "03_notes.html#returing-multiple-values",
    "title": "1  Data Structures and Sequences",
    "section": "2.2 Returing Multiple Values",
    "text": "2.2 Returing Multiple Values\nWhat’s happening here is that the function is actually just returning one object, a tuple, which is then being unpacked into the result variables.\n\ndef f():\n    a = 5\n    b = 6\n    c = 7\n    return a, b, c\n\na, b, c = f()\n\na\n\n5"
  },
  {
    "objectID": "03_notes.html#functions-are-objects",
    "href": "03_notes.html#functions-are-objects",
    "title": "1  Data Structures and Sequences",
    "section": "2.3 Functions are Objects",
    "text": "2.3 Functions are Objects\nSuppose we were doing some data cleaning and needed to apply a bunch of transformations to the following list of strings:\n\nstates = [\"   Alabama \", \"Georgia!\", \"Georgia\", \"georgia\", \"FlOrIda\",\n          \"south   carolina##\", \"West virginia?\"]\n\nimport re\n\ndef clean_strings(strings):\n    result = []\n    for value in strings:\n        value = value.strip()\n        value = re.sub(\"[!#?]\", \"\", value)\n        value = value.title()\n        result.append(value)\n    return result\n\nclean_strings(states)\n\n['Alabama',\n 'Georgia',\n 'Georgia',\n 'Georgia',\n 'Florida',\n 'South   Carolina',\n 'West Virginia']\n\n\nAnother approach\n\ndef remove_punctuation(value):\n    return re.sub(\"[!#?]\", \"\", value)\n\nclean_ops = [str.strip, remove_punctuation, str.title]\n\ndef clean_strings(strings, ops):\n    result = []\n    for value in strings:\n        for func in ops:\n            value = func(value)\n        result.append(value)\n    return result\n\nclean_strings(states, clean_ops)\n\n['Alabama',\n 'Georgia',\n 'Georgia',\n 'Georgia',\n 'Florida',\n 'South   Carolina',\n 'West Virginia']\n\n\nYou can use functions as arguments to other functions like the built-in map function\n\nfor x in map(remove_punctuation, states):\n    print(x)\n\n   Alabama \nGeorgia\nGeorgia\ngeorgia\nFlOrIda\nsouth   carolina\nWest virginia"
  },
  {
    "objectID": "03_notes.html#anonymous-lambda-functions",
    "href": "03_notes.html#anonymous-lambda-functions",
    "title": "1  Data Structures and Sequences",
    "section": "2.4 Anonymous Lambda Functions",
    "text": "2.4 Anonymous Lambda Functions\na way of writing functions consisting of a single statement\nsuppose you wanted to sort a collection of strings by the number of distinct letters in each string\n\nstrings = [\"foo\", \"card\", \"bar\", \"aaaaaaa\", \"ababdo\"]\n\nstrings.sort(key=lambda x: len(set(x)))\n\nstrings\n\n['aaaaaaa', 'foo', 'bar', 'card', 'ababdo']"
  },
  {
    "objectID": "03_notes.html#generator-expressions",
    "href": "03_notes.html#generator-expressions",
    "title": "1  Data Structures and Sequences",
    "section": "3.1 Generator expressions",
    "text": "3.1 Generator expressions\nThis is a generator analogue to list, dictionary, and set comprehensions. To create one, enclose what would otherwise be a list comprehension within parentheses instead of brackets:\n\ngen = (x ** 2 for x in range(100))\n\ngen\n\n<generator object <genexpr> at 0x7fc0d979fb50>\n\n\nGenerator expressions can be used instead of list comprehensions as function arguments in some cases:\n\nsum(x ** 2 for x in range(100))\n\n328350\n\n\n\ndict((i, i ** 2) for i in range(5))\n\n{0: 0, 1: 1, 2: 4, 3: 9, 4: 16}"
  },
  {
    "objectID": "03_notes.html#itertools-module",
    "href": "03_notes.html#itertools-module",
    "title": "1  Data Structures and Sequences",
    "section": "3.2 itertools module",
    "text": "3.2 itertools module\nitertools module has a collection of generators for many common data algorithms.\ngroupby takes any sequence and a function, grouping consecutive elements in the sequence by return value of the function\n\nimport itertools\n\ndef first_letter(x):\n    return x[0]\n\nnames = [\"Alan\", \"Adam\", \"Jackie\", \"Lily\", \"Katie\", \"Molly\"]\n\nfor letter, names in itertools.groupby(names, first_letter):\n    print(letter, list(names))\n\nA ['Alan', 'Adam']\nJ ['Jackie']\nL ['Lily']\nK ['Katie']\nM ['Molly']\n\n\nTable of other itertools functions"
  },
  {
    "objectID": "03_notes.html#exceptions-in-ipython",
    "href": "03_notes.html#exceptions-in-ipython",
    "title": "1  Data Structures and Sequences",
    "section": "4.1 Exceptions in IPython",
    "text": "4.1 Exceptions in IPython\nIf an exception is raised while you are %run-ing a script or executing any statement, IPython will by default print a full call stack trace. Having additional context by itself is a big advantage over the standard Python interpreter"
  },
  {
    "objectID": "03_notes.html#byte-and-unicode-with-files",
    "href": "03_notes.html#byte-and-unicode-with-files",
    "title": "1  Data Structures and Sequences",
    "section": "5.1 Byte and Unicode with Files",
    "text": "5.1 Byte and Unicode with Files\nThe default behavior for Python files (whether readable or writable) is text mode, which means that you intend to work with Python strings (i.e., Unicode)."
  },
  {
    "objectID": "03_video.html",
    "href": "03_video.html",
    "title": "Video",
    "section": "",
    "text": "LOG"
  },
  {
    "objectID": "04_video.html",
    "href": "04_video.html",
    "title": "Video",
    "section": "",
    "text": "LOG"
  },
  {
    "objectID": "05_main.html",
    "href": "05_main.html",
    "title": "5. Getting Started with pandas",
    "section": "",
    "text": "Learn about Pandas two major data structures: Series and DataFrame\nLearn some essential functionality!"
  },
  {
    "objectID": "05_notes.html",
    "href": "05_notes.html",
    "title": "Notes",
    "section": "",
    "text": "Note\n\n\n\nThis is a long chapter, these notes are intended as a tour of main ideas!\n\n\n\n\n\nPanda bus tour!\n\n\n\nPandas is a major tool in Python data analysis\nWorks with Numpy, adding support for tabular / heterogenous data"
  },
  {
    "objectID": "05_notes.html#import-conventions",
    "href": "05_notes.html#import-conventions",
    "title": "Notes",
    "section": "Import conventions:",
    "text": "Import conventions:\n\nimport numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "05_notes.html#pandas-primary-data-structures",
    "href": "05_notes.html#pandas-primary-data-structures",
    "title": "Notes",
    "section": "Panda’s primary data structures",
    "text": "Panda’s primary data structures\n\nSeries: One dimensional object containing a sequence of values of the same type.\nDataFrame: Tabular data, similar (and inspired by) R dataframe.\nOther structures will be introduced as they arise, e.g. Index and Groupby objects.\n\n\nSeries\n\nobj = pd.Series([4,7,-4,3], index = [\"A\",\"B\",\"C\",\"D\"])\nobj\n\nA    4\nB    7\nC   -4\nD    3\ndtype: int64\n\n\nThe index is optional, if not specified it will default to 0 through N-1\n\nSelection\nSelect elements or sub-Series by labels, sets of labels, boolean arrays …\n\nobj['A']\n\n4\n\n\n\nobj[['A','C']]\n\nA    4\nC   -4\ndtype: int64\n\n\n\nobj[obj > 3]\n\nA    4\nB    7\ndtype: int64\n\n\n\n\nOther things you can do\n\nNumpy functions and Numpy-like operations work as expected:\n\n\nobj*3\n\nA    12\nB    21\nC   -12\nD     9\ndtype: int64\n\n\n\nnp.exp(obj)\n\nA      54.598150\nB    1096.633158\nC       0.018316\nD      20.085537\ndtype: float64\n\n\n\nSeries can be created from and converted to a dictionary\n\n\nobj.to_dict()\n\n{'A': 4, 'B': 7, 'C': -4, 'D': 3}\n\n\n\nSeries can be converted to numpy array:\n\n\nobj.to_numpy()\n\narray([ 4,  7, -4,  3])\n\n\n\n\n\nDataFrame\n\nRepresents table of data\nHas row index index and column index column\nCommon way to create is from a dictionary, but see Table 5.1 for more!\n\n\ntest = pd.DataFrame({\"cars\":['Chevy','Ford','Dodge','BMW'],'MPG':[14,15,16,12], 'Year':[1979, 1980, 2001, 2020]})\ntest\n\n\n\n\n\n  \n    \n      \n      cars\n      MPG\n      Year\n    \n  \n  \n    \n      0\n      Chevy\n      14\n      1979\n    \n    \n      1\n      Ford\n      15\n      1980\n    \n    \n      2\n      Dodge\n      16\n      2001\n    \n    \n      3\n      BMW\n      12\n      2020\n    \n  \n\n\n\n\n\nIf you want a non-default index, it can be specified just like with Series.\nhead(n) / tail(n) - return the first / last n rows, 5 by default\n\n\nSelecting\n\nCan retrieve columns or sets of columns by using obj[...]:\n\n\ntest['cars']\n\n0    Chevy\n1     Ford\n2    Dodge\n3      BMW\nName: cars, dtype: object\n\n\nNote that we got a Series here.\n\ntest[['cars','MPG']]\n\n\n\n\n\n  \n    \n      \n      cars\n      MPG\n    \n  \n  \n    \n      0\n      Chevy\n      14\n    \n    \n      1\n      Ford\n      15\n    \n    \n      2\n      Dodge\n      16\n    \n    \n      3\n      BMW\n      12\n    \n  \n\n\n\n\n\nDot notation can also be used (test.cars) as long as the column names are valid identifiers\nRows can be retrieved with iloc[...] and loc[...]:\n\nloc retrieves by index\niloc retrieves by position.\n\n\n\n\nModifying / Creating Columns\n\nColumns can be modified (and created) by assignment:\n\n\ntest['MPG^2'] = test['MPG']**2\ntest\n\n\n\n\n\n  \n    \n      \n      cars\n      MPG\n      Year\n      MPG^2\n    \n  \n  \n    \n      0\n      Chevy\n      14\n      1979\n      196\n    \n    \n      1\n      Ford\n      15\n      1980\n      225\n    \n    \n      2\n      Dodge\n      16\n      2001\n      256\n    \n    \n      3\n      BMW\n      12\n      2020\n      144\n    \n  \n\n\n\n\n\ndel keyword can be used to drop columns, or drop method can be used to do so non-destructively\n\n\n\n\nIndex object\n\nIndex objects are used for holding axis labels and other metadata\n\n\ntest.index\n\nRangeIndex(start=0, stop=4, step=1)\n\n\n\nCan change the index, in this case replacing the default:\n\n\n# Create index from one of the columns\ntest.index = test['cars']  \n\n # remove 'cars' column since i am using as an index now.  s\ntest=test.drop('cars', axis = \"columns\")  # or axis  = 1\ntest\n\n\n\n\n\n  \n    \n      \n      MPG\n      Year\n      MPG^2\n    \n    \n      cars\n      \n      \n      \n    \n  \n  \n    \n      Chevy\n      14\n      1979\n      196\n    \n    \n      Ford\n      15\n      1980\n      225\n    \n    \n      Dodge\n      16\n      2001\n      256\n    \n    \n      BMW\n      12\n      2020\n      144\n    \n  \n\n\n\n\n\nNote the axis keyword argument above, many DataFrame methods use this.\nAbove I changed a column into an index. Often you want to go the other way, this can be done with reset_index:\n\n\ntest.reset_index()  # Note this doesn't actually change test\n\n\n\n\n\n  \n    \n      \n      cars\n      MPG\n      Year\n      MPG^2\n    \n  \n  \n    \n      0\n      Chevy\n      14\n      1979\n      196\n    \n    \n      1\n      Ford\n      15\n      1980\n      225\n    \n    \n      2\n      Dodge\n      16\n      2001\n      256\n    \n    \n      3\n      BMW\n      12\n      2020\n      144\n    \n  \n\n\n\n\n\nColumns are an index as well:\n\n\ntest.columns\n\nIndex(['MPG', 'Year', 'MPG^2'], dtype='object')\n\n\n\nIndexes act like immutable sets, see Table 5.2 in book for Index methods and properties"
  },
  {
    "objectID": "05_notes.html#essential-functionality",
    "href": "05_notes.html#essential-functionality",
    "title": "Notes",
    "section": "Essential Functionality",
    "text": "Essential Functionality\n\nReindexing and dropping\n\nreindex creats a new object with the values arranged according to the new index. Missing values are used if necessary, or you can use optional fill methods. You can use iloc and loc to reindex as well.\n\n\ns = pd.Series([1,2,3,4,5], index = list(\"abcde\"))\ns2 = s.reindex(list(\"abcfu\"))  #  not a song by GAYLE \ns2\n\na    1.0\nb    2.0\nc    3.0\nf    NaN\nu    NaN\ndtype: float64\n\n\n\nMissing values and can be tested for with isna or notna methods\n\n\npd.isna(s2)\n\na    False\nb    False\nc    False\nf     True\nu     True\ndtype: bool\n\n\n\ndrop , illustrated above can drop rows or columns. In addition to using axis you can use columns or index. Again these make copies.\n\n\ntest.drop(columns = 'MPG')\n\n\n\n\n\n  \n    \n      \n      Year\n      MPG^2\n    \n    \n      cars\n      \n      \n    \n  \n  \n    \n      Chevy\n      1979\n      196\n    \n    \n      Ford\n      1980\n      225\n    \n    \n      Dodge\n      2001\n      256\n    \n    \n      BMW\n      2020\n      144\n    \n  \n\n\n\n\n\ntest.drop(index = ['Ford', 'BMW'])\n\n\n\n\n\n  \n    \n      \n      MPG\n      Year\n      MPG^2\n    \n    \n      cars\n      \n      \n      \n    \n  \n  \n    \n      Chevy\n      14\n      1979\n      196\n    \n    \n      Dodge\n      16\n      2001\n      256\n    \n  \n\n\n\n\n\n\nIndexing, Selection and Filtering\n\nSeries\n\nFor Series, indexing is similar to Numpy, except you can use the index as well as integers.\n\n\nobj = pd.Series(np.arange(4.), index=[\"a\", \"b\", \"c\", \"d\"])\nobj[0:3]\n\na    0.0\nb    1.0\nc    2.0\ndtype: float64\n\n\n\nobj['a':'c']\n\na    0.0\nb    1.0\nc    2.0\ndtype: float64\n\n\n\nobj[obj<2]\n\na    0.0\nb    1.0\ndtype: float64\n\n\n\nobj[['a','d']]\n\na    0.0\nd    3.0\ndtype: float64\n\n\n\nHowever, preferred way is to use loc for selection by index and iloc for selection by position. This is to avoid the issue where the index is itself integers.\n\n\nobj.loc[['a','d']]\n\na    0.0\nd    3.0\ndtype: float64\n\n\n\nobj.iloc[1]\n\n1.0\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote if a range or a set of indexes is used, a Series is returned. If a single item is requested, you get just that item.\n\n\n\n\nDataFrame\n\nSelecting with df[...] for a DataFrame retrieves one or more columns as we have seen, if you select a single column you get a Series\nThere are some special cases, indexing with a boolean selects rows, as does selecting with a slice:\n\n\ntest[0:1]\n\n\n\n\n\n  \n    \n      \n      MPG\n      Year\n      MPG^2\n    \n    \n      cars\n      \n      \n      \n    \n  \n  \n    \n      Chevy\n      14\n      1979\n      196\n    \n  \n\n\n\n\n\ntest[test['MPG'] < 15]\n\n\n\n\n\n  \n    \n      \n      MPG\n      Year\n      MPG^2\n    \n    \n      cars\n      \n      \n      \n    \n  \n  \n    \n      Chevy\n      14\n      1979\n      196\n    \n    \n      BMW\n      12\n      2020\n      144\n    \n  \n\n\n\n\n\niloc and loc can be used to select rows as illustrated before, but can also be used to select columns or subsets of rows/columns\n\n\ntest.loc[:,['Year','MPG']]\n\n\n\n\n\n  \n    \n      \n      Year\n      MPG\n    \n    \n      cars\n      \n      \n    \n  \n  \n    \n      Chevy\n      1979\n      14\n    \n    \n      Ford\n      1980\n      15\n    \n    \n      Dodge\n      2001\n      16\n    \n    \n      BMW\n      2020\n      12\n    \n  \n\n\n\n\n\ntest.loc['Ford','MPG']\n\n15\n\n\n\nThese work with slices and booleans as well! The following says “give me all the rows with MPG more then 15, and the columns starting from Year”\n\n\ntest.loc[test['MPG'] > 15, 'Year':]\n\n\n\n\n\n  \n    \n      \n      Year\n      MPG^2\n    \n    \n      cars\n      \n      \n    \n  \n  \n    \n      Dodge\n      2001\n      256\n    \n  \n\n\n\n\n\nIndexing options are fully illustrated in the book and Table 5.4\nBe careful with chained indexing:\n\n\ntest[test['MPG']> 15].loc[:,'MPG'] = 18\n\n/Users/ronaldlegere/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1951: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.obj[selected_item_labels] = value\n\n\nHere we are assigning to a ‘slice’, which is probably not what is intended. You will get a warning and a recommendation to fix it by using one loc:\n\ntest.loc[test['MPG']> 15 ,'MPG'] = 18\ntest\n\n\n\n\n\n  \n    \n      \n      MPG\n      Year\n      MPG^2\n    \n    \n      cars\n      \n      \n      \n    \n  \n  \n    \n      Chevy\n      14\n      1979\n      196\n    \n    \n      Ford\n      15\n      1980\n      225\n    \n    \n      Dodge\n      18\n      2001\n      256\n    \n    \n      BMW\n      12\n      2020\n      144\n    \n  \n\n\n\n\n\n\n\n\n\n\nRule of Thumb\n\n\n\nAvoid chained indexing when doing assignments\n\n\n\n\n\nArithmetic and Data Alignment\n\nPandas can make it simpler to work with objects that have different indexes, usually ‘doing the right thing’\n\n\ns1 = pd.Series([7.3, -2.5, 3.4, 1.5], index=[\"a\", \"c\", \"d\", \"e\"])\ns2 = pd.Series([-2.1, 3.6, -1.5, 4, 3.1], index=[\"a\", \"c\", \"e\", \"f\", \"g\"])\ns1+s2\n\na    5.2\nc    1.1\nd    NaN\ne    0.0\nf    NaN\ng    NaN\ndtype: float64\n\n\n\nFills can be specified by using methods:\n\n\ns1.add(s2, fill_value = 0)\n\na    5.2\nc    1.1\nd    3.4\ne    0.0\nf    4.0\ng    3.1\ndtype: float64\n\n\n\nSee Table 5.5 for list of these methods.\nYou can also do arithmetic between DataFrames and Series in a way that is similar to Numpy.\n\n\n\nFunction Application and Mapping\n\nNumpy ufuncs also work with Pandas objects.\n\n\nframe = pd.DataFrame(np.random.standard_normal((4, 3)),\n                         columns=list(\"bde\"),\n                         index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\nframe\n\n\n\n\n\n  \n    \n      \n      b\n      d\n      e\n    \n  \n  \n    \n      Utah\n      0.206622\n      -0.462176\n      -0.094672\n    \n    \n      Ohio\n      -1.750506\n      1.414785\n      3.003317\n    \n    \n      Texas\n      0.703815\n      -1.269005\n      -1.327226\n    \n    \n      Oregon\n      -1.637555\n      1.192798\n      -0.614113\n    \n  \n\n\n\n\n\nnp.abs(frame)\n\n\n\n\n\n  \n    \n      \n      b\n      d\n      e\n    \n  \n  \n    \n      Utah\n      0.206622\n      0.462176\n      0.094672\n    \n    \n      Ohio\n      1.750506\n      1.414785\n      3.003317\n    \n    \n      Texas\n      0.703815\n      1.269005\n      1.327226\n    \n    \n      Oregon\n      1.637555\n      1.192798\n      0.614113\n    \n  \n\n\n\n\n\napply can be used to apply a function on 1D arrays to each column or row:\n\n\nframe.apply(np.max, axis = 'rows') #'axis' is optional here, default is rows\n\nb    0.703815\nd    1.414785\ne    3.003317\ndtype: float64\n\n\nApplying accross columns is common, especially to combine different columns in some way:\n\nframe['max'] = frame.apply(np.max, axis = 'columns')\nframe\n\n\n\n\n\n  \n    \n      \n      b\n      d\n      e\n      max\n    \n  \n  \n    \n      Utah\n      0.206622\n      -0.462176\n      -0.094672\n      0.206622\n    \n    \n      Ohio\n      -1.750506\n      1.414785\n      3.003317\n      3.003317\n    \n    \n      Texas\n      0.703815\n      -1.269005\n      -1.327226\n      0.703815\n    \n    \n      Oregon\n      -1.637555\n      1.192798\n      -0.614113\n      1.192798\n    \n  \n\n\n\n\n\nMany more examples of this in the book.\n\n\n\nSorting and Ranking\n\nsort_index will sort with the index (on either axis for DataFrame)\nsort_values is used to sort by values or a particular column\n\n\ntest.sort_values('MPG')\n\n\n\n\n\n  \n    \n      \n      MPG\n      Year\n      MPG^2\n    \n    \n      cars\n      \n      \n      \n    \n  \n  \n    \n      BMW\n      12\n      2020\n      144\n    \n    \n      Chevy\n      14\n      1979\n      196\n    \n    \n      Ford\n      15\n      1980\n      225\n    \n    \n      Dodge\n      18\n      2001\n      256\n    \n  \n\n\n\n\n\nrank will assign ranks from on through the number of data points."
  },
  {
    "objectID": "05_notes.html#summarizing-and-computing-descriptive-statistics",
    "href": "05_notes.html#summarizing-and-computing-descriptive-statistics",
    "title": "Notes",
    "section": "Summarizing and Computing Descriptive Statistics",
    "text": "Summarizing and Computing Descriptive Statistics\n\ndf = pd.DataFrame([[1.4, np.nan], [7.1, -4.5],\n                      [np.nan, np.nan], [0.75, -1.3]],\n                      index=[\"a\", \"b\", \"c\", \"d\"],\n                      columns=[\"one\", \"two\"])\ndf\n\n\n\n\n\n  \n    \n      \n      one\n      two\n    \n  \n  \n    \n      a\n      1.40\n      NaN\n    \n    \n      b\n      7.10\n      -4.5\n    \n    \n      c\n      NaN\n      NaN\n    \n    \n      d\n      0.75\n      -1.3\n    \n  \n\n\n\n\nSome Examples:\nSum over rows:\n\ndf.sum()\n\none    9.25\ntwo   -5.80\ndtype: float64\n\n\nSum over columns:\n\n# Sum Rows\ndf.sum(axis=\"columns\")\n\na    1.40\nb    2.60\nc    0.00\nd   -0.55\ndtype: float64\n\n\nExtremely useful is describe:\n\ndf.describe()\n\n\n\n\n\n  \n    \n      \n      one\n      two\n    \n  \n  \n    \n      count\n      3.000000\n      2.000000\n    \n    \n      mean\n      3.083333\n      -2.900000\n    \n    \n      std\n      3.493685\n      2.262742\n    \n    \n      min\n      0.750000\n      -4.500000\n    \n    \n      25%\n      1.075000\n      -3.700000\n    \n    \n      50%\n      1.400000\n      -2.900000\n    \n    \n      75%\n      4.250000\n      -2.100000\n    \n    \n      max\n      7.100000\n      -1.300000\n    \n  \n\n\n\n\nBook chapter contains many more examples and a full list of summary statistics and related methods."
  },
  {
    "objectID": "05_notes.html#summary",
    "href": "05_notes.html#summary",
    "title": "Notes",
    "section": "Summary",
    "text": "Summary\n\nPrimary Panda’s data structures:\n\nSeries\nDataFrame\n\nMany ways to access and transform these objects. Key ones are:\n\n[] : access an element(s) of a Series or columns(s) of a DataFrame\nloc[r ,c] : access a row / column / cell by the index.\niloc[i, j] : access ar row / column / cell by the integer position.\n\nOnline reference.\n\n\n\n\n\n\n\nSuggestion\n\n\n\nWork though the chapter’s code and try stuff!"
  },
  {
    "objectID": "05_notes.html#references",
    "href": "05_notes.html#references",
    "title": "Notes",
    "section": "References",
    "text": "References\n\nChapter’s code.\nPanda reference."
  },
  {
    "objectID": "05_notes.html#next-chapter",
    "href": "05_notes.html#next-chapter",
    "title": "Notes",
    "section": "Next Chapter",
    "text": "Next Chapter\n\nLoading and writing data sets!"
  },
  {
    "objectID": "05_video.html",
    "href": "05_video.html",
    "title": "Video",
    "section": "",
    "text": "LOG"
  },
  {
    "objectID": "06_video.html",
    "href": "06_video.html",
    "title": "Video",
    "section": "",
    "text": "LOG"
  },
  {
    "objectID": "07_video.html",
    "href": "07_video.html",
    "title": "Video",
    "section": "",
    "text": "LOG"
  },
  {
    "objectID": "08_video.html",
    "href": "08_video.html",
    "title": "Video",
    "section": "",
    "text": "LOG"
  },
  {
    "objectID": "09_video.html",
    "href": "09_video.html",
    "title": "Video",
    "section": "",
    "text": "LOG"
  },
  {
    "objectID": "10_video.html",
    "href": "10_video.html",
    "title": "Video",
    "section": "",
    "text": "LOG"
  },
  {
    "objectID": "11_video.html",
    "href": "11_video.html",
    "title": "Video",
    "section": "",
    "text": "LOG"
  },
  {
    "objectID": "12_video.html",
    "href": "12_video.html",
    "title": "Video",
    "section": "",
    "text": "LOG"
  },
  {
    "objectID": "example_quarto.html",
    "href": "example_quarto.html",
    "title": "Example Quarto Document",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "example_quarto.html#running-code",
    "href": "example_quarto.html#running-code",
    "title": "Example Quarto Document",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n2\n\n\nYou can add options to executable code like this\n\n\n4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "example_python.html",
    "href": "example_python.html",
    "title": "Example Jupyter Notebook",
    "section": "",
    "text": "import numpy as np\na = np.arange(15).reshape(3, 5)\na\n\narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14]])"
  },
  {
    "objectID": "example_python.html#matplotlib",
    "href": "example_python.html#matplotlib",
    "title": "Example Jupyter Notebook",
    "section": "Matplotlib",
    "text": "Matplotlib\n\nimport matplotlib.pyplot as plt\n\nfig = plt.figure()\nx = np.arange(10)\ny = 2.5 * np.sin(x / 20 * np.pi)\nyerr = np.linspace(0.05, 0.2, 10)\n\nplt.errorbar(x, y + 3, yerr=yerr, label='both limits (default)')\nplt.errorbar(x, y + 2, yerr=yerr, uplims=True, label='uplims=True')\nplt.errorbar(x, y + 1, yerr=yerr, uplims=True, lolims=True,\n             label='uplims=True, lolims=True')\n\nupperlimits = [True, False] * 5\nlowerlimits = [False, True] * 5\nplt.errorbar(x, y, yerr=yerr, uplims=upperlimits, lolims=lowerlimits,\n             label='subsets of uplims and lolims')\n\nplt.legend(loc='lower right')\nplt.show(fig)"
  },
  {
    "objectID": "how-to.html",
    "href": "how-to.html",
    "title": "How to add to the book",
    "section": "",
    "text": "This book is made with Quarto. Please see the Get Started chapter of the Quarto documentation to learn how to install and run Quarto in your IDE."
  },
  {
    "objectID": "how-to.html#add-to-book",
    "href": "how-to.html#add-to-book",
    "title": "How to add to the book",
    "section": "Add to book",
    "text": "Add to book\nOnce you have everything set up, forked the repo, and cloned to your computer, you can add a new chapter to the book.\nCreate a new file in the repository folder. For example, to create a new file called 01_exercises.qmd, navigate to the folder then create one using touch 01_exercises.qmd. If you are using VSCode, you can use the Quarto plug-in. You can use plain .md files, Quarto .qmd, or Jupyter .ipynb files in this book. Check out the files under Examples to see the various options.\nWrite in what you would like in the file.\nThen, in the _quarto.yml file, under chapters, add a part with your chapter. The file listed after part is the first page of chapter; the ones under chapters will be subpages.\n  - part: 01_main.qmd\n      chapters: \n      - 01_notes.qmd\n      - 01_video.qmd\n      - 01_exercises.qmd"
  },
  {
    "objectID": "how-to.html#render-the-book",
    "href": "how-to.html#render-the-book",
    "title": "How to add to the book",
    "section": "Render the book",
    "text": "Render the book\nOnce you have added and edited your files, don’t forget to render the book. Run this in the terminal:\nquarto render --to html"
  },
  {
    "objectID": "how-to.html#push-up-to-github",
    "href": "how-to.html#push-up-to-github",
    "title": "How to add to the book",
    "section": "Push up to GitHub",
    "text": "Push up to GitHub\nPush your changes to your forked repo and then create a pull request for the R4DS admins to merge your changes.\ngit add .\ngit commit -m \"Message here\"\ngit push"
  }
]